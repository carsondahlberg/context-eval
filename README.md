Tools for Evaluation of Unsupervised Word Sense Disambiguation Systems
====

This repository contains tools for evaluation of unsupervised word sense disambiguation (WSD) and lexical substitution also known as systems aka "contextualization" system. The scripts are based on TWSI 2.0 and SemEval 2013 datasets.  

```
:'######:::'#######::'##::: ##:'########:'########:'##::::'##:'########:::::::'########:'##::::'##::::'###::::'##:::::::
'##... ##:'##.... ##: ###:: ##:... ##..:: ##.....::. ##::'##::... ##..:::::::: ##.....:: ##:::: ##:::'## ##::: ##:::::::
 ##:::..:: ##:::: ##: ####: ##:::: ##:::: ##::::::::. ##'##:::::: ##:::::::::: ##::::::: ##:::: ##::'##:. ##:: ##:::::::
 ##::::::: ##:::: ##: ## ## ##:::: ##:::: ######:::::. ###::::::: ##::::'####: ######::: ##:::: ##:'##:::. ##: ##:::::::
 ##::::::: ##:::: ##: ##. ####:::: ##:::: ##...:::::: ## ##:::::: ##::::.....: ##...::::. ##:: ##:: #########: ##:::::::
 ##::: ##: ##:::: ##: ##:. ###:::: ##:::: ##:::::::: ##:. ##::::: ##:::::::::: ##::::::::. ## ##::: ##.... ##: ##:::::::
. ######::. #######:: ##::. ##:::: ##:::: ########: ##:::. ##:::: ##:::::::::: ########:::. ###:::: ##:::: ##: ########:
:......::::.......:::..::::..:::::..:::::........::..:::::..:::::..:::::::::::........:::::...:::::..:::::..::........::

```


Installation
============

1. Clone repository.
2. Make sure that environment is setup: The default Python should be is 2.7. Currently Python 3 is not supported. The script was tested on Mac OSX and Linux. In principle, it should work on Windows under Cygwin. The script also requires Java 1.7 or higher. 
3. Install dependencies: ```pip install pandas spacy```.


SemEval 2013 Task 13 Evaluation
==================

1. Fill column ```predict_sense_ids``` of the lexical sample dataset ```data/Dataset-SemEval-2013-13.csv```. Example of the result: https://github.com/tudarmstadt-lt/contextualization-eval/blob/master/data/Dataset-SemEval-2013-13-clean-lemma-model-alpha-05-norelated.csv

2. Run the evaluation script:

  ```
  usage: semeval_2013_13.sh <path-to-golden.key> <path-to-system.dataset>
  example: semeval_2013_13.sh semeval_2013_13/keys/gold/all.key data/Dataset-SemEval-2013-13-adagram-ukwac-wacky-raw.csv
  ```

  Evaluation scores will be printed to standard output. 

  For more details about the this evaluation dataset refer to: http://www.aclweb.org/website/old_anthology/S/S13/S13-2.pdf#page=326

TWSI Evaluation
==============

The tool evaluates Word Sense Disambiguation performance of a custom WSD system utilizing sentences and word senses (consisting of contextualized word substitutions) from the [Turk Bootstrap Word Sense Inventory TWSI 2.0](https://www.lt.informatik.tu-darmstadt.de/de/data/twsi-turk-bootstrap-word-sense-inventory/)

First, it aligns the provided word sense inventory to TWSI senses. The alignment is calculated as the maximum overlap between related terms from a provided word sense to the substitutions from TWSI. After alignment, it calculates the precision, recall and F-score of the WSD system.


Evaluation 
--------------------

1. Clone repository:

   ```
    git clone https://github.com/tudarmstadt-lt/contextualization-eval.git
    ```

2. Install dependencies:
    ```
    pip install numpy scipy pandas
    ```

3. Fill with your program columns ```predict_sense_ids``` and ```predict_related``` in ```data/Dataset-TWSI-2.csv``` and save it (you can use as an example ```data/Dataset-TWSI-2-sample.csv```). The first one contains a list of relevant sense identifiers for a given context and the second contains a list of contextually semantically related words. Check columns ```golden_sense_ids``` and ```golden_related``` for example. Data formats: https://github.com/tudarmstadt-lt/contextualization-eval#input-data-format-datadataset-twsi-20csv. If your system cannot confidently classify some sense i.e. implements a "reject option" during classification you can set ```-1``` in the ```predict_sense_id```. In this case coverage of your system will be less than 0.999. 

4. Create your word sense inventory needed for mapping senses to the gold standard word sense inventory. A sample file is available at: ```data/Inventory-sample.csv```

5. Evaluate your predictions, based on your word sense inventory ```, e.g.:

    ```
    python twsi_evaluation.py data/Inventory-TWSI-2.csv data/Dataset-TWSI-2-GOLD.csv.gz
    ```

    If your Dataset-TWSI-2-GOLD.csv file has no header then use the following argument:
    
    ```
    python twsi_evaluation.py data/Inventory-TWSI-2.csv  data/Dataset-TWSI-2-GOLD-no-header.csv.gz --no_header
    ```

    Results of the evaluations are printed to stdout. Most essential metrics are also printed to stderr. You should see something like this:

    ```
    Evaluation Results:
    Correct, retrieved, nr_sentences
    25465 	63801 	  142644
    Precision: 0.399131675052 	Recall: 0.17852135386 	F1: 0.246700089612
    Coverage:  0.447274333305
    ```

Data Format
---------------

###Input data format: *data/Dataset-TWSI-2.0.csv*
To be able to run different evaluation scripts, the TWSI 2.0 data needs to be converted into a different format. Int the *data/* folder, you will find the transformed TWSI data. 

```
context_id  target-lemma   target_POS  target_position   gold_IDs predicted_IDs  gold_related_words   predicted_related_words context
```
####Example
```
10038908       ability n       160,169 1              aptitude:2, strength:4, talent:11, comprehension:1, function:2, competence:1, faculty:3, capability:33, capacity:29, skill:19             The following year , Harchester United reached the Semi Finals of the FA Cup and were also promoted back to the Premiership thanks to the fantastic goalscoring abilities of Karl Fletcher . 
1418247        ability n       45,54   1              aptitude:2, strength:4, talent:11, comprehension:1, function:2, competence:1, faculty:3, capability:33, capacity:29, skill:19             He has also more than once overestimated his abilities or at times is often too na√Øve or cocky which usually results in a disadvantage during battle . 
...
```

###Word Sense Inventory: *data/word_sense_inventory.csv*

The sense inventory should be in two columns. The first column contains the word lemma, the second column contains the sense identifier for the lemma.
In the third columns, there is a list of related terms. Each of the related terms can be weighted by a number. These numbers are separated by colons ':'.

```
Word  SenseID  list:5,of:3,related:1,words:1
```
####Example
```
mouse 0        mammalian:50,murine:20,Drosophila:10,human:9
mouse 1        rat:200,mice:150,frog:80,sloth:50,rodent:40
mouse 2        joystick:50,keyboard:33,monitor:25,simulation:15
...
```
## TWSI Input data

### Contexts: data/data/TWSI-2.0-all-contexts.txt

We provide the contents from TWSI 2.0 in their original format (tab separated). In the provided file, we have compiled all the contexts that TWSI 2.0 offers.

Format:

```
TWSI_SenseID   target_word    surface_form     sentenceID   tokenized_sentence   confidence_score
```
The sentences are tokenized and contain a '\<b\>' tag around the target word. Additionally, the target word and its surface form are listed in separate columns.

####Example
```
ability@@1  	ability  	abilities   	10038908	   The following year , Harchester United reached the Semi Finals of the FA Cup and were also promoted back to the Premiership thanks to the fantastic goalscoring <b>abilities</b> of Karl Fletcher . 	   1.0
```

#### Extraction

To extract this data, you can just concatenate all the .context files from TWSI:
```
cat path/to/TWSI2_complete/contexts/*.contexts > data/TWSI-2.0-all-contexts.txt
```

#### Conversion to common format

To convert the TWSI format to the one used in our evaluation, you can use the utils/utils/transform-TWSI.pl script.
It requires the TWSI contexts file as well as the TWSI sense inventory:
```
perl utils/transform-TWSI.pl data/TWSI-2.0-all-contexts.txt data/TWSI-2.0-sense-inventory.txt 
```


### TWSI Sense Inventory: data/TWSI-2.0-sense-inventory.txt 

The TWSI sense inventory follows the format for sense inventories: https://github.com/tudarmstadt-lt/contextualization-eval#word-sense-inventory-dataword_sense_inventorycsv

You can extract the TWSI sense inventory, by running the following command:

####Example

```
academic@@1	scholastic:21, educational:13, scholarly:9, university:5
academic@@2	school:3, educational:2, scholastic:2, school calendar:1
academic@@3	scholar:35, professor:11, academician:10, teacher:9, lecturer:8
```

####Extraction

```
find path/to/TWSI2_complete/substitutions/raw_data/all-substitutions/ -name \*.turk* | sort | xargs perl utils/extract-TWSI-inventory.pl > data/TWSI-2.0-sense-inventory.txt 
```

License
-----------
TWSI 2.0 is licensed under the Creative Commons Attribution-ShareAlike 3.0 Unported license (https://creativecommons.org/licenses/by-sa/3.0/). The combined TWSI 2.0 sentences are shared under the same license.

The code of the evaluation script is under the Apache Software License (ASL) 2.0 (http://www.apache.org/licenses/LICENSE-2.0).


References
-------------
* [Biemann and Nygaard, 2010] C. Biemann and V. Nygaard (2010): Crowdsourcing WordNet.  In Proceedings of the 5th Global WordNet conference, Mumbai, India. 
* [Biemann, 2012] C. Biemann (2012): Turk Bootstrap Word Sense Inventory 2.0:  A Large-Scale Resource for Lexical Substitution. Proceedings of LREC 2012, Istanbul, Turkey.
